{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "520f9587-f999-4a6d-b58d-53a0e68276c4",
   "metadata": {},
   "source": [
    "適当なまとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5c4e6-a002-46ae-8b6f-504cbb2cd26f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 線形回帰\n",
    "+ 最小二乗法、最尤推定\n",
    "  + 相関係数が±１に近い特徴量の組を　__作らないように__　各組の相関係数を観ながら特徴量をうまく取り除く\n",
    "+ 重回帰分析　…　多重共線性に注意"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77327b8-afd8-4e31-87e7-51f5eead0790",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 単回帰分析の流れ   \n",
    "> $\\hat{y} = a * x + b$\n",
    "1. (x, y) = (目的変数の __観測値__ 、説明変数の __観測値__ )（観測データ）を用意\n",
    "2. (x, y)から最小二乗法で単回帰直線の式（モデル）を求める\n",
    "3. 式を決定係数Rで評価\n",
    "4. 評価の結果が __良ければ、__ モデルに説明変数の __観測値__ を　$x$ に入れて予測値$\\hat{y}$を求める\n",
    "\n",
    "回帰直線　…　観測データの各点との残差が最も小さくなるようにする\n",
    "\n",
    "最小二乗法　$a = \\frac{s_x}{s_y},   b = \\bar{y} - a*\\bar{x}$\n",
    "\n",
    "決定係数　…　１　- （偏差の平方和）/（偏差の全平方和）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf5d22-d67c-411b-b2d8-b131cb0c8ead",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 重回帰分析の流れ   \n",
    "> $\\hat{y} = a_1 * x_1 + a_2 * x_2 + ... + a_n * x_n + b$\n",
    "1. (x, y) = $(x_1, x_2, ... , x_n, y)$（観測データ）を用意\n",
    "2. (x, y)から最小二乗法で単回帰直線の式（モデル）を求める\n",
    "3. 式を決定係数$R^2$で評価\n",
    "4. 評価の結果が __良ければ、__ モデルに説明変数の __観測値__ を　$x$ に入れて予測値$\\hat{y}$を求める\n",
    "\n",
    "回帰直線　…　観測データの各点との残差が最も小さくなるようにする\n",
    "\n",
    "決定係数　…　$\\frac{S_\\hat{y}}{S_y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a49691-7f51-49e7-8594-f5892288be3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# サポート・ベクター・マシン\n",
    "+ 2つのクラスを綺麗に分ける\n",
    "+ __マージン最大化__　\n",
    "  + ソフトマージンSVM …　データにノイズが混じっている場合にも対応したSVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4110bce6-1bd7-41e2-a083-4a5b25645898",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# ニューラルネットワーク\n",
    "+ 入力される電気信号の電位（重みx入力の総和）がある閾値を超えると発火し、シナプス（活性化関数）によって次のニューロン（ノード）に電気信号を出力、それを繰り返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c713c-6563-4876-b18d-27223623681b",
   "metadata": {},
   "source": [
    "## 単純パーセプトロン\n",
    "+ 重みは勾配降下法（教師データを与えた、誤差関数Eの最小化のための繰り返し計算）によって更新される\n",
    "+ 重み=現在の重み　- 学習率xEの勾配"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b84beec-5f35-434d-a52b-50dbf06fa419",
   "metadata": {},
   "source": [
    "## 多層パーセプトロン\n",
    "+ 入力層、中間層、出力層\n",
    "+ 重みは確率的勾配降下法（教師データを与えた、誤差関数Eの最小化のための繰り返し計算）によって更新される\n",
    "+ 重み=現在の重み　- 学習率xEの勾配　\n",
    "+ 活性化関数\n",
    "  + 中間層 ... ReLU（勾配消失問題が発生しない）\n",
    "  + 出力層付近 ... ソフトマックス関数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cdc26f-4ca5-4ed1-aad2-ffb86382cb5c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 深層学習\n",
    "+ ニューラルネットワークを用いた（多層化した）機械学習の手法\n",
    "+ __順伝播__ と __逆伝播__ の繰り返し\n",
    "  + 順伝播　…　訓練データを用いた予測\n",
    "  + 逆伝播　…　誤差が最小となるように勾配降下法で重みを更新\n",
    "+ メリット\n",
    "  + 複雑なモデルを構築できる\n",
    "+ デメリット\n",
    "  + ハイパーパラメータが多い\n",
    "  + 過学習が多い\n",
    "  + 勾配消失問題が起こる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34c4abb-2ad9-4734-9248-2f7bbb40821d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 用語集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fda6800-d358-472d-9c41-968684836d5c",
   "metadata": {},
   "source": [
    "+ 勾配降下法\n",
    "+ 局所最適解\n",
    "+ 大域的最適解\n",
    "+ 停留点\n",
    "+ エポック数\n",
    "+ イテレーション集\n",
    "+ 逐次学習\n",
    "+ バッチ学習\n",
    "+ ミニバッチ学習\n",
    "+ 勾配消失問題\n",
    "+ 正解率\n",
    "+ 適合率\n",
    "+ 再現率\n",
    "+ F値"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87a0e34-69bb-4202-9fc0-5e2e0c6f3068",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 畳み込みニューラルネットワーク（CNN)\n",
    "> ディープラーニングの手法の一つ、画像認識で使われる\n",
    "> \n",
    "> 入力層、畳み込み層、プーリング層、全結合層、出力層　で構成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc2d21b-10a6-486e-a688-37899a50f62a",
   "metadata": {},
   "source": [
    "## 畳み込み層\n",
    "> 特徴量の取り出し\n",
    "> \n",
    "> 輪郭抽出、ぼかし処理などの空間フィルタリング\n",
    "+ 畳み込み演算\n",
    "  + ２次元の入力データに対してフィルタを用いる、入力が３次元の場合はフィルタも３つ\n",
    "  + ゼロパディング・ストライド ... 出力画像のサイズを調整\n",
    "  \n",
    "## プーリング層\n",
    "> 入力データの圧縮\n",
    "> \n",
    "> ロバスト性の向上、過学習防止、計算コストの抑制\n",
    "+ Max Pooling\n",
    "  + 入力データの小領域から最大値のみ取り出す\n",
    "  \n",
    "## 全結合層\n",
    "> 多層パーセプトロンと同様\n",
    "+ $y = f(w_1*x_1 + w_2*x_2 + b)$\n",
    "  + 入力ユニットの値と、接続の重みを内積してバイアスを加える, fは活性化関数"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
